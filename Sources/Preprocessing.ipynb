{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8bdd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615ffa22",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20720/3080704503.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data/clean.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kitty\\pycharmprojects\\testaffichage\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kitty\\pycharmprojects\\testaffichage\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kitty\\pycharmprojects\\testaffichage\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kitty\\pycharmprojects\\testaffichage\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kitty\\pycharmprojects\\testaffichage\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1038\u001B[0m             )\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kitty\\pycharmprojects\\testaffichage\\venv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kitty\\pycharmprojects\\testaffichage\\venv\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \"\"\"\n\u001B[1;32m--> 222\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kitty\\pycharmprojects\\testaffichage\\venv\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    699\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    700\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 701\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    702\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    703\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/clean.csv'"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"data/clean.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = []\n",
    "qualitative= []\n",
    "\n",
    "for variable in df.columns.tolist():\n",
    "    if df.dtypes[variable] in ['float64','int64']:\n",
    "        numeric.append(variable)\n",
    "    else :\n",
    "        qualitative.append(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c958dc8",
   "metadata": {},
   "source": [
    "##### Test de normalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapiro_test(x):\n",
    "    try :\n",
    "        res = stats.shapiro(x)\n",
    "    except :\n",
    "        return -1\n",
    "    alpha = 0.05\n",
    "\n",
    "    print(\"p = \",res.pvalue)\n",
    "\n",
    "    if res.pvalue < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "\n",
    "        print(\"(shapiro)The null hypothesis can be rejected -> X ne possède pas une distribution normale\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"(shapiro) The null hypothesis cannot be rejected -> X possède éventuellement une distribution normale\")\n",
    "\n",
    "    return res\n",
    "\n",
    "def omnibus_normaltest(x):\n",
    "    #test D'Agostino-Pearson\n",
    "    try :\n",
    "        k2, p = stats.normaltest(x)\n",
    "    except :\n",
    "        return -1\n",
    "    \n",
    "    alpha = 0.05\n",
    "\n",
    "    print(\"p = \",p)\n",
    "\n",
    "    if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "\n",
    "        print(\"(normaltest) The null hypothesis can be rejected -> X ne possède pas une distribution normale\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"(normaltest) The null hypothesis cannot be rejected -> X possède éventuellement une distribution normale\")\n",
    "\n",
    "    return [k2,p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14338d8e",
   "metadata": {},
   "source": [
    "## valeur missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(df):\n",
    "    df_null = pd.DataFrame([df.isnull().sum(),round(100*df.isnull().sum()/ len(df), 2), df.dtypes]).transpose().reset_index()\n",
    "    df_null.columns = [\"variable\", \"valeur_NA\", \"Pourcentage_NA\", \"type\"]\n",
    "    df_null = df_null[df_null.valeur_NA != 0].sort_values(\"valeur_NA\",ascending = False).reset_index(drop = True)\n",
    "    return df_null\n",
    "missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8841a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.columns[data.isnull().sum() / len(data) > 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=data.copy()\n",
    "df = d.drop('division_af',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=list(data.columns[data.isnull().sum() / len(data) < 0.05])\n",
    "for i in list(d):\n",
    "    df = df.dropna(subset=[i], axis=0)\n",
    "missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d60f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fonction_af'] = df['fonction_af'].fillna(df['fonction_af'].mode()[0])\n",
    "df['direction_af'] = df['direction_af'].fillna(df['direction_af'].mode()[0])\n",
    "df['motif_affect'] = df['motif_affect'].fillna(df['motif_affect'].mode()[0])\n",
    "df['service_af'] = df['service_af'].fillna(df['service_af'].mode()[0])\n",
    "df['job_act'] = df['job_act'].fillna(df['job_act'].mode()[0])\n",
    "\n",
    "d=list(df.columns[df.isnull().sum() / len(df) < 0.05])\n",
    "for i in list(d):\n",
    "    df = df.dropna(subset=[i], axis=0)\n",
    "    \n",
    "from sklearn.impute import KNNImputer\n",
    "df[numeric]=KNNImputer(missing_values=np.nan, n_neighbors=3).fit_transform(df[numeric])\n",
    "df[numeric] = np.round(df[numeric],decimals = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd766635",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tot_afct'].plot(figsize=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2bf7c",
   "metadata": {},
   "source": [
    "## Valeur aberante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "Outliers_to_drop = detect_outliers(df,0,numeric)\n",
    "# df.drop(Outliers_to_drop,0,inplace=True)\n",
    "len(Outliers_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6aa57",
   "metadata": {},
   "source": [
    "## Teste de normalite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fccdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk Test\n",
    "from scipy.stats import shapiro\n",
    "def Shapiro(d):\n",
    "    stat, p = shapiro(d)\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    # interpret\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')\n",
    "    \n",
    "for i in numeric:\n",
    "    print(i)\n",
    "    Shapiro(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "def agostino_test(d):\n",
    "    stat, p = normaltest(d)\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    # interpret\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')\n",
    "    \n",
    "for i in numeric:\n",
    "    agostino_test(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = {}\n",
    "for col in numeric:\n",
    "    print(\"\\n\",col)\n",
    "    Shapiro(np.log(df[col].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176fd217",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[qualitative[4]].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "formation=['ECONOMIE CIRCULAIRE ET DEVELOPPEMENT DURABLE','CFEPENN','2EME REUNION DES EXPERTS DE','AGOA','FORMATION','SCANNER','RAPPROCHEMENT DES DONNEES COMPTABLES','RENFORCEMENT','SEMINAIRE','LUTTE','SURVEILLANCE','ATELIER','TECHNIQUE D\\'ENQUETE','SCANNER','DACTYLOGRAPHIE','FOOD SAFETY INSPECTION TECHNOLOGY','COMMUNICATION INTERPERSONNELLE','ACCUEIL DES USAGERS','SURETE AEROPORTUAIRE','ATELIER SUR LES NEGOCIATIONS SUR LA ZLET TRIPARTITE','VALEUR TRANSACTIONNELLE','COMPTABILITE','BAE','MECANICIEN','CONTROLE A POSTERIORI','OPERATEUR IMAGE SCANNER','TABLEAU DE BORD','CORRESPONDANCE ADMINISTRATIVE','ATTACHE D\\'ADMINISTRATION','REGLES D\\'ORIGINE','SECRETARIAT','TEAM MANAGEMENT','DEVELOPPEMENT PERSONNEL','GESTION AXEE SUR LES RESULTATS','SECRETARIAT','MISE A NIVEAU','MECANIQUE AUTOMOBILE','MANAGEMENT ET LEADERSHIP','BUREAUTIQUE','LEADERSHIP','FORMATION']\n",
    "MAITRISE=['DUES','4E ANNEE','BACC+4','BACC+5','SECOND CYCLE',\"DIPLOME D'ETUDES PROFESSIONNELLES APPROFONDIES\",'4EME ANNEE','MASTER','MAITRISE','ETHIQUE ET DEONTOLOGIE','DEA','MAGISTERE','INGENIORAT','INGENIEUR','2ND CYCLE','BACCALAUREAT+4']\n",
    "LICENCE =['3EME ANNEE','BACC+3','LICENCE']\n",
    "BREVET=['BREVET','CFEPCES','PREBAC','PRE BAC','BEPC']\n",
    "PRIMAIRE=['CAE/EB','CEPE','CERTIFICAT D\\'ETUDES PRIMAIRES ELEMENTAIRES']\n",
    "DOUANE=['SYDONIA++','PROCEDURE DE DEDOUANEMENT','DOUAN','TRANSIT']\n",
    "LANGUES=['B1-B2','ANGLAIS','FRANCAIS','DELF','ENGLISH','MTCP']\n",
    "INFORMATIQUE=['ANALYSE D\\'IMAGE','ATTESTATION','ELECTRONIQUE','ELECTROTECHNIQUE','PROGRAMMATION','DEVELOPPEUR','SOFTWARE','BASE DE DONNEE','ORACLE','EXCEL','WEB','LINUX','GRAPHISTE','RESEAU','INFORMATIQUE','PROGRAMMEUR']\n",
    "PERMIS=['PERMIS','MAINTENANCE AUTOMOBILE','CHAUFFEUR','MECANIQUE AUTO','CONDUCTEUR']\n",
    "BACC=['BACC','BACALAUREAT']\n",
    "SUPERIEUR=['BT','BATIMENT','COMPTABLE','AUDIT INTERNE','DROIT','GESTION','DROIT / GEOGRAPHIE','MANAGEMENT','DIPLOME','INFA','IST-T','COMMUNICATION','SUPERIEUR','UNIVERSITAIRE','COACHING','CHEF','BANCAIRES','INTERNATIONALES','ETUDES APPROFONDIES','SERVICE NATIONAL HORS FORCES ARMEES','RADIOPROTECTION','ETUDES JUDICIAIRES','CONTROLE A LA CIRCULATION','MARCHE PUBLIC','ENVIRONNEMENT','OZONE','SURETE AEROPORTUAIRE ET FRAUDE DOCUMENTAIRE','SUBSTANCES APPAUVRISSANT LA COUCHE D\\'OZONE','COMMERCE INTERNATIONAL','CITES','CONTROLE DES SUBSTANCES APPAUVRISSANT LA COUCHE D\\'OZONE','DIPLOME D\\'ATTACHE D\\'ADMINISTRATION']\n",
    "DTS=['2E ANNEE','DEUG','2EME ANNEE','BACC+2','DTS']\n",
    "Autres=['FORMATION','MAITRISE','LICENCE','BREVET','PRIMAIRE','DOUANE','LANGUES','INFORMATIQUE','PERMIS','BACC','SUPERIEUR','DTS']\n",
    "dat = list(df[qualitative[4]])\n",
    "for index, value in enumerate(dat):\n",
    "    for i in DTS:\n",
    "        if i in str(value):\n",
    "            dat[index]='DTS'\n",
    "    for i in BACC:\n",
    "        if i in str(value):\n",
    "            dat[index]='BACC'\n",
    "    for i in SUPERIEUR:\n",
    "        if i in str(value):\n",
    "            dat[index]='SUPERIEUR'\n",
    "    for i in PERMIS:\n",
    "        if i in str(value):\n",
    "            dat[index]='PERMIS'\n",
    "    for i in INFORMATIQUE:\n",
    "        if i in str(value):\n",
    "            dat[index]='INFORMATIQUE'\n",
    "    for i in LANGUES:\n",
    "        if i in str(value):\n",
    "            dat[index]='LANGUES'\n",
    "    for i in DOUANE:\n",
    "        if i in str(value):\n",
    "            dat[index]='DOUANE'\n",
    "    for i in PRIMAIRE:\n",
    "        if i in str(value):\n",
    "            dat[index]='PRIMAIRE'\n",
    "    for i in BREVET:\n",
    "        if i in str(value):\n",
    "            dat[index]='BREVET'\n",
    "    for i in LICENCE:\n",
    "        if i in str(value):\n",
    "            dat[index]='LICENCE'\n",
    "    for i in formation:\n",
    "        if str(i) in str(value):\n",
    "            dat[index]='FORMATION'\n",
    "    for i in MAITRISE:\n",
    "        if i in str(value):\n",
    "            dat[index]='MAITRISE'\n",
    "    if 'CERTIFICAT' in str(value):\n",
    "        dat[index]='CERTIFICAT'\n",
    "    if 'DOCTORAT' in str(value):\n",
    "        dat[index]='DOCTORAT'\n",
    "        \n",
    "df[qualitative[4]] =  dat\n",
    "d = list(df[qualitative[4]])\n",
    "for index, value in enumerate(d):\n",
    "    if  str(value) not in Autres:\n",
    "        print(value)\n",
    "        d[index]='Autres'\n",
    "df[qualitative[4]] =  d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dafd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPerLevels(data,list_feature):\n",
    "    catHead = ['Feature', 'Level', 'Count', 'Frequence %']\n",
    "    count = []\n",
    "    freq = []\n",
    "    feature_all = []\n",
    "    list_level_all = []\n",
    "    for feature in list_feature:\n",
    "        \n",
    "        list_level = data[feature].unique().tolist()\n",
    "\n",
    "        len_level = len(list_level)\n",
    "\n",
    "        for level in list_level:\n",
    "            count_level = len(data.loc[data[feature] == level])\n",
    "            count.append(count_level)\n",
    "            freq_level = count_level * 100/len(data)\n",
    "            freq.append(round(freq_level, 2))\n",
    "            feature_all.append(feature)\n",
    "            list_level_all.append(level)\n",
    "    \n",
    "    resultDf = pd.DataFrame(columns=catHead)\n",
    "    resultDf['Level'] = list_level_all\n",
    "    resultDf['Feature'] = feature_all\n",
    "    resultDf['Count'] = count\n",
    "    resultDf['Frequence %'] = freq\n",
    "    resultDf.set_index(['Feature', 'Level'], inplace=True)\n",
    "    return resultDf\n",
    "processPerLevels(df,[qualitative[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[qualitative[15]].unique()))\n",
    "processPerLevels(df,[qualitative[15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb79a7",
   "metadata": {},
   "source": [
    "## log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d1caf",
   "metadata": {},
   "source": [
    "## Stendardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5623f45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'data/preproce.csv',index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}